<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Deterministic View of Diffusion Models | Hui Jiang </title> <meta name="author" content="Hui Jiang"> <meta name="description" content="In this post, we present a deterministic perspective on diffusion models. In this approach, neural networks are trained as an inverse function of the deterministic diffusion mapping that progressively corrupts images at each time step. This method simplifies the derivation of diffusion models, enabling us to fully explain and derive them using only a few straightforward mathematical equations."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/huijiang/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/huijiang/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/huijiang/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/huijiang/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://incml.github.io/huijiang/blog/2024/Deterministic-Diffusion-Models/"> <script src="/huijiang/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/huijiang/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/huijiang/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/huijiang/assets/js/distillpub/template.v2.js"></script> <script src="/huijiang/assets/js/distillpub/transforms.v2.js"></script> <script src="/huijiang/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "A Deterministic View of Diffusion Models",
            "description": "In this post, we present a deterministic perspective on diffusion models. In this approach, neural networks are trained as an inverse function of the deterministic diffusion mapping that progressively corrupts images at each time step. This method simplifies the derivation of diffusion models, enabling us to fully explain and derive them using only a few straightforward mathematical equations.",
            "published": "November 11, 2024",
            "authors": [
              
              {
                "author": "Hui Jiang",
                "authorURL": "https://www.cse.yorku.ca/~huijiang",
                "affiliations": [
                  {
                    "name": "York University, Toronto, Canada",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/huijiang//"> <span class="font-weight-bold">Hui</span> Jiang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/huijiang/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/huijiang/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/huijiang/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/huijiang/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/huijiang/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/huijiang/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/huijiang/students/">students </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>A Deterministic View of Diffusion Models</h1> <p>In this post, we present a deterministic perspective on diffusion models. In this approach, neural networks are trained as an inverse function of the deterministic diffusion mapping that progressively corrupts images at each time step. This method simplifies the derivation of diffusion models, enabling us to fully explain and derive them using only a few straightforward mathematical equations.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#deterministic-forward-diffusion-process">Deterministic Forward Diffusion Process</a> </div> <div> <a href="#deterministic-backward-denoising-process">Deterministic Backward Denoising Process</a> </div> <div> <a href="#the-deterministic-diffusion-models">The Deterministic Diffusion Models</a> </div> <ul> <li> <a href="#i-estimating-clean-image">I. Estimating clean image</a> </li> <li> <a href="#ii-estimating-noise">II. Estimating noise</a> </li> </ul> <div> <a href="#final-remarks">Final Remarks</a> </div> </nav> </d-contents> <p>In recent years, diffusion models, a novel category of deep generative models <d-cite key="JiangMLF2021"></d-cite>, have made significant strides in producing high-quality, high-resolution images. Notable examples include GLIDE <d-cite key="nichol2022glidephotorealisticimagegeneration"></d-cite>, DALLE-2 <d-cite key="ramesh2022hierarchicaltextconditionalimagegeneration"></d-cite>, Imagen <d-cite key="saharia2022photorealistictexttoimagediffusionmodels"></d-cite>, and the fully open-source Stable Diffusion <d-cite key="rombach2022highresolutionimagesynthesislatent"></d-cite>. These models are traditionally developed based on the framework of Denoising Diffusion Probabilistic Models (DDPM) <d-cite key="ho2020denoisingdiffusionprobabilisticmodels"></d-cite>. In this probabilistic framework, the forward diffusion process is modeled as a Gaussian process with Markovian properties. Conversely, the backward denoising process employs neural networks to estimate the conditional distribution at each time step. The neural networks involved in the denoising process are trained to minimize the evidence lower bound (ELBO) <d-cite key="ho2020denoisingdiffusionprobabilisticmodels"></d-cite> <d-cite key="luo2022understandingdiffusionmodelsunified"></d-cite>, akin to the approach used in a Variational Autoencoder (VAE) <d-cite key="Kingma_2019"></d-cite>.</p> <p>In this post, we present a deterministic perspective on diffusion models. In this method, neural networks are constructed to function in the opposite way of a deterministic diffusion process that gradually deteriorates images over time. This training allows the neural networks to reconstruct or generate images by reversing the diffusion process without using any knowledge of stochastic process. This method simplifies the derivation of diffusion models, making the process more straightforward and comprehensible. Within this deterministic framework, diffusion models can be fully explained and derived from scratch using only a few straightforward mathematical equations, as shown in this concise, self-contained post. This approach requires only basic mathematical knowledge, eliminating the need for lengthy tutorials filled with hundreds of complex equations involving stochastic processes and probability distributions. <d-cite key="luo2022understandingdiffusionmodelsunified"></d-cite>.</p> <h2 id="deterministic-forward-diffusion-process"><strong>Deterministic Forward Diffusion Process</strong></h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-480.webp 480w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-800.webp 800w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Figure 1. A deterministic view of diffusion models in the forward diffusion process and the backward denoising transformation (Image adapted from <d-cite key="karagiannakos2022diffusionmodels"></d-cite>). </div> <p>In Figure 1, we illustrate a deterministic view of the typical diffusion process in diffusion models. Starting with any input clean image, denoted as \(\mathbf{x}_0\), the forward process incrementally corrupts the input image for each time step \(t=1,2,\cdots,T\). This corruption is achieved by progressively adding varying levels of Gaussian noises over time as</p> \[\mathbf{x}_t = \sqrt{\alpha_t } \mathbf{x}_{t-1} + \sqrt{1- \alpha_t } \, {\boldsymbol \epsilon}_t \;\;\; \forall t=1, 2, \cdots, T\] <p>adhering to a predefined noise schedule: \(\alpha_1, \alpha_2, \ldots, \alpha_T\), where the noise at each timestep is Gaussian, \({\boldsymbol \epsilon}_t \sim \mathcal{N}(0, \mathbf{I})\). This process gradually introduces more noise at each step, leading to a sequence of increasingly corrupted versions of the original image: \(\mathbf{x}_0 \to \mathbf{x}_1 \to \mathbf{x}_2 \to \cdots \to \mathbf{x}_T\). When \(T\) is large enough, the last image \(\mathbf{x}_T\) approaches to a Gaussian noise, i.e. \(\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})\).</p> <p>Building on the so-called “nice property” outlined in <d-cite key="ho2020denoisingdiffusionprobabilisticmodels"></d-cite> <d-cite key="luo2022understandingdiffusionmodelsunified"></d-cite> <d-cite key="karagiannakos2022diffusionmodels"></d-cite>, the above diffusion process can be implemented much more efficiently. Rather than sampling a unique Gaussian noise at each time step, it is feasible to sample a single Gaussian noise, \(\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})\), and employ the subsequent formula to efficiently generate all the corrupted samples in one go (along the left-to-right red dash arrow in Figure 1):</p> \[\begin{align} \mathbf{x}_t = f(\mathbf{x}_{0}, {\boldsymbol \epsilon}, t) = \sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_t} \, {\boldsymbol \epsilon} \;\;\; \forall t=1, 2, \cdots, T \label{eq-forward-deterministic} \end{align}\] <p>where \(\bar{\alpha}_t = \prod_{s=1}^t \alpha_s\) and we have \(\bar{\alpha}_t \to 0\) as \(t \to T\).</p> <p>In the diffusion process described in Eq. (\ref{eq-forward-deterministic}), once the noise \({\boldsymbol \epsilon}\) is sampled, it is treated as constant for the whole diffusion process. Consequently, the transformation from the clean image \(\mathbf{x}_{0}\) to noisy images \(\mathbf{x}_{t}\) at each time step \(t\) can be regarded as a deterministic mapping, characterized by the above function \(\mathbf{x}_t = f(\mathbf{x}_{0}, {\boldsymbol \epsilon}, t)\).</p> <p>As shown in Figure 2, clean images are gradually converted into pure noises in the above deterministic diffusion process as \(t\) goes from \(0\) to \(T\). The method in Eq.(\ref{eq-forward-deterministic}) streamlines the process, making the generation of corrupted samples more straightforward and less computationally demanding.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-process-480.webp 480w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-process-800.webp 800w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-process-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic-diffusion-process.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Figure 2. The deterministic diffussion process of some images selected from the MNIST-Fashion dataset. </div> <h2 id="deterministic-backward-denoising-process"><strong>Deterministic Backward Denoising Process</strong></h2> <p>If the forward diffusion process is treated as deterministic, the corresponding deterministic mappings for the backward denoising process – transforming any noisy image \(\mathbf{x}_{t}\) back to the clean image \(\mathbf{x}_{0}\) – can also be derived.</p> <p>Here, let’s explore the relationship between \(\mathbf{x}_{t-1}\) and \(\mathbf{x}_t\) in the above diffusion process. This exploration will help us understand how consecutive stages in the diffusion process are linked by a deterministic function, which is essential for the subsequent deterministic denoising methods. In fact, it is possible to establish this deterministic function connecting two consecutive samples using two different approaches.</p> <p><strong>(1)</strong> In the first method, assuming the noise \({\boldsymbol \epsilon}\) is known, we can rearrange eq.(\ref{eq-forward-deterministic}) for the time step, \(t\), as follows:</p> \[\begin{align} \mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} \big[ \mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\, {\boldsymbol \epsilon} \big] \label{eq-forwar-t} \end{align}\] <p>Furthermore, according to Eq.(\ref{eq-forward-deterministic}), for the previous time step \(t-1\), we have the following:</p> \[\begin{align} \mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t-1}} \, {\boldsymbol \epsilon} \label{eq-forwar-t-1} \end{align}\] <p>We may substitue Eq.(\ref{eq-forwar-t}) into the above equation to derive the first relationship between any two adjacent samples as follows:</p> \[\begin{align} \begin{aligned} \mathbf{x}_{t-1} &amp;= \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t-1}} \, {\boldsymbol \epsilon} \\ &amp;= \frac{1}{\sqrt{\alpha_t}} \big[ \mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\, {\boldsymbol \epsilon} \big] + \sqrt{1 - \bar{\alpha}_{t-1}} \, {\boldsymbol \epsilon} \\ &amp;= \frac{1}{\sqrt{\alpha_t}} \Big[ \mathbf{x}_t - \big( \sqrt{1-\bar{\alpha}_t} - \sqrt{\alpha_t-\bar{\alpha}_t} \big) {\boldsymbol \epsilon} \Big] \end{aligned} \label{eq-consecutive-time-noise} \end{align}\] <p><strong>(2)</strong> Alternatively, assuming the original clean image \(\mathbf{x}_{0}\) is known, we can rearrange Eq.(\ref{eq-forward-deterministic}) as follows</p> \[{\boldsymbol \epsilon} = \frac{1}{\sqrt{1 - \bar{\alpha}_{t}}} \big[ \mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_{0}\big]\] <p>and substitute \({\boldsymbol \epsilon}\) into Eq.(\ref{eq-forwar-t-1}), we have</p> \[\begin{aligned} \mathbf{x}_{t-1} &amp;= \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t-1}} \, {\boldsymbol \epsilon} \\ &amp;= \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0} + \frac{\sqrt{1 - \bar{\alpha}_{t-1}}}{\sqrt{1 - \bar{\alpha}_{t}}} \big[ \mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_{0}\big] \\ \end{aligned}\] <p>If we denote</p> \[\bar{\gamma}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}}\] <p>we can simplify the above equation as follows:</p> \[\begin{align} \mathbf{x}_{t-1} = \sqrt{\bar{\gamma}_t} \, \mathbf{x}_t + \big( \sqrt{\bar{\alpha}_{t-1}} - \sqrt{\bar{\gamma}_t \bar{\alpha}_t} \big) \mathbf{x}_0 \label{eq-consecutive-time-x0} \end{align}\] <p>However, in practice, we cannot directly use Eq. (\ref{eq-consecutive-time-noise}) or Eq. (\ref{eq-consecutive-time-x0}) to derive \(\mathbf{x}_{t-1}\) from \(\mathbf{x}_t\) during the backward denoising process, as neither the noise \({\boldsymbol \epsilon}\) nor the original clean image ​\(\mathbf{x}_0\) is known. The key insight of diffusion models is that neural networks can be trained to approximate the inverse of the deterministic mapping function \(\mathbf{x}_t = f(\mathbf{x}_{0},\boldsymbol \epsilon, t)\) in the forward process. By leveraging this inverse mapping, the learned neural networks can help to estimate either the noise \({\boldsymbol \epsilon}\) or the original clean image ​\(\mathbf{x}_0\) from a noisy image \(\mathbf{x}_t\). There are two approaches for training neural networks, denoted as \({\boldsymbol \theta}\), to approximate this inverse function:</p> <ol> <li> <p>Approximate the inverse mapping from \(\mathbf{x}_t\) to the clean image \(\mathbf{x}_0\), i.e. \(\mathbf{\hat x}_0 = f^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\), allowing Eq. (\ref{eq-consecutive-time-x0}) to be applied for the backward denoising process. This inverse mapping is shown as the right-to-left red dash arrow in Figure 1.</p> </li> <li> <p>Approximate the inverse mapping from \(\mathbf{x}_t\) to the noise \({\boldsymbol \epsilon}\), i.e. \(\hat{\boldsymbol \epsilon} = g^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\), enabling the use of Eq. (\ref{eq-consecutive-time-noise}) for the backward denoising process.</p> </li> </ol> <p>Next, we will briefly explore these two different types of deterministic diffusion models.</p> <h2 id="the-deterministic-diffusion-models"><strong>The Deterministic Diffusion Models</strong></h2> <p>In the backward process, starting from a Gaussian noise</p> \[\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})\] <p>we may gradually recover all corrupted images backwards one by one until we obtain the initial clean image:</p> \[\mathbf{x}_T \to \mathbf{x}_{T-1} \to \mathbf{x}_{T-2} \to \cdots \to \mathbf{x}_1 \to \mathbf{x}_0\] <p>Alternatively, at any time step \(t\), given the corrupted image \(\mathbf{x}_t\), we may also directly estimate the original clean image \(\mathbf{x}_0\) based on \(\mathbf{x}_t\). If the estimate is good enough, we can terminate the backward denoising process at an earlier stage; Otherwise, we further denoise one time step backwards, i.e. deriving \(\mathbf{x}_{t-1}\) from \(\mathbf{x}_t\). Based on \(\mathbf{x}_{t-1}\), we may derive a better estimate of the clean image \(\mathbf{x}_0\). This denoising process continues until we finally obtain a sufficiently good clean image \(\mathbf{x}_0\).</p> <p>In the above backward denoising process, to obtain a slightly cleaner image \(\mathbf{x}_{t-1}\) from \(\mathbf{x}_{t}\) using either Eq. (\ref{eq-consecutive-time-x0}) or Eq. (\ref{eq-consecutive-time-noise}), we have two options for training neural networks to approximate the inverse mapping, as previously discussed.</p> <h3 id="i-estimating-clean-image-mathbfx_0"><strong>I. Estimating clean image \(\mathbf{x}_0\)</strong></h3> <p>In this case, we construct a deep neural network \(\boldsymbol \theta\) to approximate the inverse function of the above diffusion mapping \(\mathbf{x}_t = f(\mathbf{x}_0, {\boldsymbol \epsilon}, t)\), denoted as</p> \[\mathbf{\hat x}_0 = f^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\] <p>which can recover a rough estimate of the clean image \(\hat{\mathbf{x}}_0\) from any \(\mathbf{x}_t\) (along the right-to-left red dash arrow in Figure 1). In this case, the neural network is learned by minimizing the following objective function over all training data in the training set \(\mathcal{D}\):</p> \[\begin{aligned} L_1({\boldsymbol \theta}) &amp;= \sum_{\mathbf{x}_0 \in \mathcal{D}} \sum_{t=1}^T \Big( f^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t) - \mathbf{x}_0\Big)^2 \\ &amp;= \sum_{\mathbf{x}_0 \in \mathcal{D}} \sum_{t=1}^T \Big( f^{-1}_{\boldsymbol \theta} \big(\sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_t} \, {\boldsymbol \epsilon}, t \big) - \mathbf{x}_0\Big)^2 \end{aligned}\] <p>Once the neural network \(\boldsymbol \theta\) has been trained, Eq. (\ref{eq-consecutive-time-x0}) can be used to perform the backward denoising process:</p> \[\begin{aligned} \mathbf{x}_{t-1} &amp;= \sqrt{\bar{\gamma}_t} \, \mathbf{x}_t + \big( \sqrt{\bar{\alpha}_{t-1}} - \sqrt{\bar{\gamma}_t \bar{\alpha}_t} \big) \hat{\mathbf{x}}_0 \\ &amp;= \sqrt{\bar{\gamma}_t} \, \mathbf{x}_t + \big( \sqrt{\bar{\alpha}_{t-1}} - \sqrt{\bar{\gamma}_t \bar{\alpha}_t} \big) f^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t) \\ \end{aligned}\] <p>The corresponding sampling process to generate a new image can be described as follows:</p> <ul> <li>sample a Gaussian noise \(\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})\)</li> <li> <strong>for</strong> \(t=T, T-1, \cdots, 1\): <ul> <li>use the trained neural network \({\boldsymbol \theta}\) to compute</li> </ul> \[\hat{\mathbf{x}}_0 = f^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\] <ul> <li> <strong>if</strong> \(\hat{\mathbf{x}}_0\) is stable <strong>or</strong> \(t=1\), return \(\hat{\mathbf{x}}_0\)</li> <li> <strong>else</strong> denoise one step backward as</li> </ul> </li> </ul> \[\mathbf{x}_{t-1} = \sqrt{\bar{\gamma}_t} \, \mathbf{x}_t + \big( \sqrt{\bar{\alpha}_{t-1}} - \sqrt{\bar{\gamma}_t \bar{\alpha}_t} \big) \hat{\mathbf{x}}_0\] <p>In Figure 3, we have shown some sampling results from the MNIST-Fashion dataset through the above sampling algorithm via building neural networks to estimate clean images.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_cleanimage-480.webp 480w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_cleanimage-800.webp 800w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_cleanimage-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_cleanimage.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Figure 3. Some sampling results are shown from the MNIST-Fashion dataset via building neural networks to estimate clean images. Every two lines represent one sampling example: the first line displays denoising samples at each timestep while the second line shows the estimated clean image at each timestep. </div> <h3 id="ii-estimating-noise-boldsymbol-epsilon"><strong>II. Estimating noise \({\boldsymbol \epsilon}\)</strong></h3> <p>In this case, we construct a deep neural network \(\boldsymbol \theta\) to approximate the inverse function via estimating the noise \({\boldsymbol \epsilon}\) from a corrupted image \(\mathbf{x}_t\) at each time step \(t\):</p> \[\hat{\boldsymbol \epsilon} = g^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\] <p>This neural network is learned by minimizing the following objective function over all training data:</p> \[\begin{aligned} L_2({\boldsymbol \theta}) &amp;= \sum_{\mathbf{x}_0 \in \mathcal{D}} \sum_{t=1}^T \Big( g^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t) - {\boldsymbol \epsilon}\Big)^2 \\ &amp;= \sum_{\mathbf{x}_0 \in \mathcal{D}} \sum_{t=1}^T \Big( g^{-1}_{\boldsymbol \theta} \big(\sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_t} \, {\boldsymbol \epsilon}, t \big) - {\boldsymbol \epsilon}\Big)^2 \end{aligned}\] <p>Once the neural network is learned, we can use Eq.(\ref{eq-consecutive-time-noise}) to derive an estimate of \(\mathbf{x}_{t-1}\) from \(\mathbf{x}_{t}\) as follows:</p> \[\begin{aligned} \mathbf{x}_{t-1} &amp;= \frac{1}{\sqrt{\alpha_t}} \Big[ \mathbf{x}_t - \big( \sqrt{1-\bar{\alpha}_t} - \sqrt{\alpha_t-\bar{\alpha}_t} \big) \hat{\boldsymbol \epsilon} \Big] \\ &amp;= \frac{1}{\sqrt{\alpha_t}} \Big[ \mathbf{x}_t - \big( \sqrt{1-\bar{\alpha}_t} - \sqrt{\alpha_t-\bar{\alpha}_t} \big) g^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t) \Big] \end{aligned}\] <p>Similarly, the corresponding sampling process to generate a new image can be described as follows:</p> <ul> <li> <p>sample a Gaussian noise \(\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})\)</p> </li> <li> <p><strong>for</strong> \(t=T, T-1, \cdots, 1\):</p> <ul> <li>use the trained neural network \({\boldsymbol \theta}\) to compute:</li> </ul> \[\hat{\boldsymbol \epsilon} = g^{-1}_{\boldsymbol \theta} (\mathbf{x}_t, t)\] <ul> <li>estimate clean image as in Eq.(\ref{eq-forwar-t}):</li> </ul> \[\hat{\mathbf{x}}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} \big[ \mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\, \hat{\boldsymbol \epsilon} \big]\] <ul> <li> <p><strong>if</strong> \(\hat{\mathbf{x}}_0\) is stable <strong>or</strong> \(t=1\), return \(\hat{\mathbf{x}}_0\)</p> </li> <li> <p><strong>else</strong> denoise one step backward as</p> </li> </ul> \[\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \Big[ \mathbf{x}_t - \big( \sqrt{1-\bar{\alpha}_t} - \sqrt{\alpha_t-\bar{\alpha}_t} \big) \hat{\boldsymbol \epsilon} \Big]\] </li> </ul> <p>In Figure 4, we have shown some sampling results from the MNIST-Fashion dataset via building neural networks to estimate noises through the above sampling algorithm.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_noise-480.webp 480w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_noise-800.webp 800w,/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_noise-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/huijiang/assets/img/2024-11-11-Deterministic-Diffusion-Models/deterministic_denoising_via_noise.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Figure 4. Some sampling results are shown from the MNIST-Fashion dataset via building neural networks to estimate noises. Every two lines represent one sampling example: the first line displays denoising samples at each timestep while the second line shows the estimated clean image at each timestep. </div> <h2 id="final-remarks"><strong>Final Remarks</strong></h2> <p>In recent years, diffusion models have become increasingly significant in computer vision, emerging as the dominant models for images and videos across a wide range of real-world applications. However, the traditional approach to understanding diffusion models presents a steep learning curve, as it requires advanced mathematical knowledge in areas such as probability density estimation, stochastic process, and differential equation <d-cite key="ho2020denoisingdiffusionprobabilisticmodels"></d-cite> <d-cite key="luo2022understandingdiffusionmodelsunified"></d-cite>. In this post, we have introduced a new deterministic perspective on diffusion models, enabling us to fully explain and derive them using only a few straightforward mathematical equations. Moreover, we have found that the two methods presented in this post are essentially equivalent to the Denoising Diffusion Implicit Models (DDIMs) method discussed in <d-cite key="song2022denoisingdiffusionimplicitmodels"></d-cite>. However, our methods are derived through a much simpler and more intuitive approach compared to the procedure outlined in <d-cite key="song2022denoisingdiffusionimplicitmodels"></d-cite>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/huijiang/assets/bibliography/2024-11-11-Deterministic-Diffusion-Models.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Hui Jiang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/huijiang/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/huijiang/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/huijiang/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/huijiang/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/huijiang/blog/"}},{id:"nav-publications",title:"publications",description:"a selection of my recent publications (since 2014) by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/huijiang/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of my cool projects.",section:"Navigation",handler:()=>{window.location.href="/huijiang/projects/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/huijiang/repositories/"}},{id:"nav-teaching",title:"teaching",description:"List of courses I taught at York University.",section:"Navigation",handler:()=>{window.location.href="/huijiang/teaching/"}},{id:"nav-students",title:"students",description:"a list of all my current and former graduate students and postdocs",section:"Navigation",handler:()=>{window.location.href="/huijiang/students/"}},{id:"post-a-brief-introduction-to-bitcoin",title:"A Brief Introduction to Bitcoin",description:"In this post, we provide a concise introduction to the key technologies that underpin the Bitcoin network. This overview highlights several important implementations within Bitcoin and offers readers the foundational knowledge needed to understand how the network operates.",section:"Posts",handler:()=>{window.location.href="/huijiang/blog/2025/Bitcoin/"}},{id:"post-a-deterministic-view-of-diffusion-models",title:"A Deterministic View of Diffusion Models",description:"In this post, we present a deterministic perspective on diffusion models. In this approach, neural networks are trained as an inverse function of the deterministic diffusion mapping that progressively corrupts images at each time step. This method simplifies the derivation of diffusion models, enabling us to fully explain and derive them using only a few straightforward mathematical equations.",section:"Posts",handler:()=>{window.location.href="/huijiang/blog/2024/Deterministic-Diffusion-Models/"}},{id:"post-understanding-transformers-and-gpt-an-in-depth-overview",title:"Understanding Transformers and GPT: An In-depth Overview",description:"In this post, we delve into the technical details of the widely used transformer architecture by deriving all formulas involved in its forward and backward passes step by step. By doing so, we can implement these passes ourselves and often achieve more efficient performance than using autograd methods. Additionally, we introduce the technical details on the construction of the popular GPT-3 model using the transformer architecture.",section:"Posts",handler:()=>{window.location.href="/huijiang/blog/2023/Transformer-GPT/"}},{id:"post-machine-learning-fundamentals",title:"Machine Learning Fundamentals",description:"Supplementary materials for the book &quot;Machine Learning Fundamentals&quot;, published by Cambridge University Press.",section:"Posts",handler:()=>{window.location.href="/huijiang/blog/2022/Machine-Learning-Fundamentals/"}},{id:"news-my-new-book-machine-learning-fundamentals-is-published",title:"My new book \u201cMachine Learning Fundamentals\u201d is published.",description:"",section:"News",handler:()=>{window.location.href="/huijiang/news/announcement_0/"}},{id:"news-my-personal-website-is-moved-here-from-yorku-eecs-server-https-wiki-eecs-yorku-ca-user-hj",title:"My personal website is moved here from [YorkU EECS server](https://wiki.eecs.yorku.ca/user/hj/).",description:"",section:"News"},{id:"projects-deterministic-diffussion-models",title:"Deterministic Diffussion Models",description:"This project redirects to a Jupyter Notebook at Google Colab for study and experiments.",section:"Projects",handler:()=>{window.location.href="/huijiang/projects/project_DDM/"}},{id:"projects-machine-learning-fundamentals",title:"Machine Learning Fundamentals",description:"\xa9Hui Jiang 2021, Cambridge University Press",section:"Projects",handler:()=>{window.location.href="/huijiang/projects/project_MLF/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%75%69%6A%69%61%6E%67@%79%6F%72%6B%75.%63%61","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=lQi05ZkAAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/36357862","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Hui-Jiang-13/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iNCML","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hui-jiang-8b860630","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/huijiang313","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/huijiang/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>